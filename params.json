{
  "name": "Classifying MNIST digits using Convolutional Neural Networks",
  "tagline": "",
  "body": "# Classifying MNIST digits using Convolutional Neural Networks\r\n\r\nIn this project, I show how TensorFlow can be used to implement convolutional neural networks.\r\nAlso, I briefly introduce basic concepts of convolutional neural networks.\r\nThe mathematical notations and its mapping TensowFlow graphs can be seen at below.\r\nThe accuracy of this model for Kaggle competition: **0.99**\r\n\r\n## MNIST dataset\r\nLink: http://yann.lecun.com/exdb/mnist/\r\n> The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\r\nIt is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. \r\n\r\n\r\n## Kaggle competition on digit recognizer\r\nLink: https://www.kaggle.com/c/digit-recognizer\r\n\r\nThe goal in this competition is to take an image of a handwritten single digit, and determine what that digit is.  As the competition progresses, we will release tutorials which explain different machine learning algorithms and help you to get started.\r\n\r\n\r\nThe data for this competition were taken from the MNIST dataset. The MNIST (\"Modified National Institute of Standards and Technology\") dataset is a classic within the Machine Learning community that has been extensively studied.  More detail about the dataset, including Machine Learning algorithms that have been tried on it and their levels of success, can be found at http://yann.lecun.com/exdb/mnist/index.html.\r\n\r\n\r\n### Competition dataset\r\nThe data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\r\n\r\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\r\n\r\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\r\n\r\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\r\n\r\nFor example, pixel31 indicates the pixel that is in the fourth column from the left, and the second row from the top, as in the ascii-diagram below.\r\n\r\nVisually, if we omit the \"pixel\" prefix, the pixels make up the image like this:\r\n```\r\n000 001 002 003 ... 026 027\r\n028 029 030 031 ... 054 055\r\n056 057 058 059 ... 082 083\r\n |   |   |   |  ...  |   |\r\n728 729 730 731 ... 754 755\r\n756 757 758 759 ... 782 783 \r\n```\r\nThe test data set, (test.csv), is the same as the training set, except that it does not contain the \"label\" column.\r\n\r\nYour submission file should be in the following format: For each of the 28000 images in the test set, output a single line with the digit you predict. For example, if you predict that the first image is of a 3, the second image is of a 7, and the third image is of a 8, then your submission file would look like:\r\n```\r\n3\r\n7\r\n8\r\n(27997 more lines)\r\n```\r\n\r\nThe evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that you have correctly classified all but 3% of the images.\r\n\r\n### Libraries and settings\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nimport tensorflow as tf\r\n\r\n# Parameters\r\nLEARNING_RATE = 0.001\r\nTRAINING_EPOCHS = 3000\r\nBATCH_SIZE = 100\r\nDISPLAY_STEP = 10\r\nDROPOUT_CONV = 0.8\r\nDROPOUT_HIDDEN = 0.6\r\nVALIDATION_SIZE = 2000      # Set to 0 to train on all available data\r\n```\r\n\r\n### Data preparation\r\nTo start, we read given train and test data from each csv file. At first we read train.csv file.\r\n```python\r\n# Read MNIST data set (Train data from CSV file)\r\ndata = pd.read_csv('./input/train.csv')\r\n```\r\n\r\nThe data contains label and written images for number. `[label pixel_0, pixel_1, ... , pixel_784]`\r\nSo, we split data into label and image from each row.\r\n```python\r\n# Extracting images and labels from given data\r\n# For images\r\nimages = data.iloc[:,1:].values\r\nimages = images.astype(np.float)\r\n\r\n# For labels\r\nlabels_flat = data[[0]].values.ravel()\r\nlabels_count = np.unique(labels_flat).shape[0]\r\n```\r\n\r\nFor easy implementation of output layer, we convert label with number into ont-hot-vector.\r\nYou can refer the idea of one-hot on this [link](https://en.wikipedia.org/wiki/One-hot).\r\n\r\nFor example, we convert the numbers as follow: \r\n`0:[1 0 0 0 0 0 0 0 0 0]`\r\n`1:[0 1 0 0 0 0 0 0 0 0]`\r\n...\r\n`9:[0 0 0 0 0 0 0 0 0 1]`\r\n```python\r\nlabels = dense_to_one_hot(labels_flat, labels_count)\r\nlabels = labels.astype(np.uint8)\r\n```\r\n\r\n```python\r\ndef dense_to_one_hot(labels_dense, num_classes):\r\n    num_labels = labels_dense.shape[0]\r\n    index_offset = np.arange(num_labels) * num_classes\r\n    labels_one_hot = np.zeros((num_labels, num_classes))\r\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\r\n    return labels_one_hot\r\n```\r\n\r\nThen we normalize the intensity of each pixel from [0:255] into [0.0:1:0]\r\n\r\n```python\r\n# Normalize from [0:255] => [0.0:1.0]\r\nimages = np.multiply(images, 1.0 / 255.0)\r\nimage_size = images.shape[1]\r\nimage_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\r\n```\r\n\r\nBefore applying our trained model to test data, we validate our trained model using validation dataset.\r\nSo, we split training data into [train, validation].\r\n```python\r\n# Split data into training & validation\r\nvalidation_images = images[:VALIDATION_SIZE]\r\nvalidation_labels = labels[:VALIDATION_SIZE]\r\n\r\ntrain_images = images[VALIDATION_SIZE:]\r\ntrain_labels = labels[VALIDATION_SIZE:]\r\n\r\n```\r\n\r\n\r\n### Create CNN model with TensorFlow graph\r\n\r\nWe start creating cnn model with definition of input and output.\r\nThis model handle each image and make decision for the image with digit classes [0-9].\r\n```python\r\n# Create Input and Output\r\nX = tf.placeholder('float', shape=[None, image_size])       # mnist data image of shape 28*28=784\r\nY_gt = tf.placeholder('float', shape=[None, labels_count])    # 0-9 digits recognition => 10 classes\r\n```\r\n\r\nUsing below functions, we can generate weight and bias easily.\r\nBasically, the simple weight and bias are generated on normal distribution.\r\nFor better result, we implemented Xavier's initialization with input and output connections.\r\nFor the detail explanation, you can refer two blogs: [deepdish](http://deepdish.io/2015/02/24/network-initialization/) and [andyljones](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization).\r\n```python\r\n# Weight initialization\r\ndef weight_variable(shape):\r\n    initial = tf.truncated_normal(shape, stddev=0.1)\r\n    return tf.Variable(initial)\r\n\r\n# Weight initialization (Xavier's init)\r\ndef weight_xavier_init(n_inputs, n_outputs, uniform=True):\r\n    if uniform:\r\n        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\r\n        return tf.random_uniform_initializer(-init_range, init_range)\r\n    else:\r\n        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\r\n        return tf.truncated_normal_initializer(stddev=stddev)\r\n\r\n# Bias initialization\r\ndef bias_variable(shape):\r\n    initial = tf.constant(0.1, shape=shape)\r\n    return tf.Variable(initial)\r\n```\r\n\r\nUsing above functions, we make two convolutional layers, and two fully connected layers.\r\n\r\n```python\r\n# Model Parameters\r\nW1 = tf.get_variable(\"W1\", shape=[5, 5, 1, 32], initializer=weight_xavier_init(5*5*1, 32))\r\nW2 = tf.get_variable(\"W2\", shape=[5, 5, 32, 64], initializer=weight_xavier_init(5*5*32, 64))\r\nW3_FC1 = tf.get_variable(\"W3_FC1\", shape=[64*7*7, 1024], initializer=weight_xavier_init(64*7*7, 1024))\r\nW4_FC2 = tf.get_variable(\"W4_FC2\", shape=[1024, labels_count], initializer=weight_xavier_init(1024, labels_count))\r\n\r\nB1 = bias_variable([32])\r\nB2 = bias_variable([64])\r\nB3_FC1 = bias_variable([1024])\r\nB4_FC2 = bias_variable([labels_count])\r\n\r\ndrop_conv = tf.placeholder('float')\r\ndrop_hidden = tf.placeholder('float')\r\n```\r\n\r\n### Model description\r\nAt first, we transform from 1D input vector into 2D image. \r\nFor the convolutional layer, we apply three steps:\r\n\r\n1. Convolution\r\n1. Max-pooling\r\n1. Dropout\r\n\r\nFor the fully connected layer, the process is same with basic neural network.\r\n\r\n```python\r\n# CNN model\r\nX1 = tf.reshape(X, [-1,image_width , image_height,1])                   # shape=(?, 28, 28, 1)\r\n    \r\n# Layer 1\r\nl1_conv = tf.nn.relu(conv2d(X1, W1) + B1)                               # shape=(?, 28, 28, 32)\r\nl1_pool = max_pool_2x2(l1_conv)                                         # shape=(?, 14, 14, 32)\r\nl1_drop = tf.nn.dropout(l1_pool, drop_conv)\r\n\r\n# Layer 2\r\nl2_conv = tf.nn.relu(conv2d(l1_drop, W2)+ B2)                           # shape=(?, 14, 14, 64)\r\nl2_pool = max_pool_2x2(l2_conv)                                         # shape=(?, 7, 7, 64)\r\nl2_drop = tf.nn.dropout(l2_pool, drop_conv) \r\n\r\n# Layer 3 - FC1\r\nl3_flat = tf.reshape(l2_drop, [-1, W3_FC1.get_shape().as_list()[0]])    # shape=(?, 1024)\r\nl3_feed = tf.nn.relu(tf.matmul(l3_flat, W3_FC1)+ B3_FC1) \r\nl3_drop = tf.nn.dropout(l3_feed, drop_hidden)\r\n\r\n\r\n# Layer 4 - FC2\r\nY_pred = tf.nn.softmax(tf.matmul(l3_drop, W4_FC2)+ B4_FC2)              # shape=(?, 10)\r\n```\r\n\r\n### Cost function and Training\r\nWe define cross-entropy for the cost function.\r\nAnd penalize using L2-regularization.\r\n```python\r\n# Cost function and training \r\ncost = -tf.reduce_sum(Y_gt*tf.log(Y_pred))\r\nregularizer = (tf.nn.l2_loss(W3_FC1) + tf.nn.l2_loss(B3_FC1) + tf.nn.l2_loss(W4_FC2) + tf.nn.l2_loss(B4_FC2))\r\ncost += 5e-4 * regularizer\r\n\r\n#train_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cost)\r\ntrain_op = tf.train.RMSPropOptimizer(LEARNING_RATE, 0.9).minimize(cost)\r\ncorrect_predict = tf.equal(tf.argmax(Y_pred, 1), tf.argmax(Y_gt, 1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_predict, 'float'))\r\npredict = tf.argmax(Y_pred, 1)\r\n```\r\n\r\n### TensorFlow session\r\n```python\r\nepochs_completed = 0\r\nindex_in_epoch = 0\r\nnum_examples = train_images.shape[0]\r\n\r\n# start TensorFlow session\r\ninit = tf.initialize_all_variables()\r\nsess = tf.InteractiveSession()\r\n\r\nsess.run(init)\r\n\r\n# visualisation variables\r\ntrain_accuracies = []\r\nvalidation_accuracies = []\r\n\r\nDISPLAY_STEP=1\r\n\r\nfor i in range(TRAINING_EPOCHS):\r\n\r\n    #get new batch\r\n    batch_xs, batch_ys = next_batch(BATCH_SIZE)        \r\n\r\n    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\r\n    if i%DISPLAY_STEP == 0 or (i+1) == TRAINING_EPOCHS:\r\n        \r\n        train_accuracy = accuracy.eval(feed_dict={X:batch_xs, \r\n                                                  Y_gt: batch_ys,\r\n                                                  drop_conv: DROPOUT_CONV, \r\n                                                  drop_hidden: DROPOUT_HIDDEN})       \r\n        if(VALIDATION_SIZE):\r\n            validation_accuracy = accuracy.eval(feed_dict={ X: validation_images[0:BATCH_SIZE], \r\n                                                            Y_gt: validation_labels[0:BATCH_SIZE],\r\n                                                            drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})                                  \r\n            print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d'%(train_accuracy, validation_accuracy, i))\r\n            \r\n            validation_accuracies.append(validation_accuracy)\r\n            \r\n        else:\r\n             print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\r\n        train_accuracies.append(train_accuracy)\r\n        \r\n        # increase DISPLAY_STEP\r\n        if i%(DISPLAY_STEP*10) == 0 and i:\r\n            DISPLAY_STEP *= 10\r\n    # train on batch\r\n    sess.run(train_op, feed_dict={X: batch_xs, Y_gt: batch_ys, drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})\r\n\r\n\r\n# check final accuracy on validation set  \r\nif(VALIDATION_SIZE):\r\n    validation_accuracy = accuracy.eval(feed_dict={X: validation_images, \r\n                                                   Y_gt: validation_labels,\r\n                                                   drop_conv: DROPOUT_CONV, drop_hidden: DROPOUT_HIDDEN})\r\n    print('validation_accuracy => %.4f'%validation_accuracy)\r\n\r\n# read test data from CSV file \r\ntest_images = pd.read_csv('./input/test.csv').values\r\ntest_images = test_images.astype(np.float)\r\n\r\n# convert from [0:255] => [0.0:1.0]\r\ntest_images = np.multiply(test_images, 1.0 / 255.0)\r\n\r\nprint('test_images({0[0]},{0[1]})'.format(test_images.shape))\r\n\r\n\r\n# predict test set\r\n#predicted_lables = predict.eval(feed_dict={X: test_images, keep_prob: 1.0})\r\n\r\n# using batches is more resource efficient\r\npredicted_lables = np.zeros(test_images.shape[0])\r\nfor i in range(0,test_images.shape[0]//BATCH_SIZE):\r\n    predicted_lables[i*BATCH_SIZE : (i+1)*BATCH_SIZE] = predict.eval(feed_dict={X: test_images[i*BATCH_SIZE : (i+1)*BATCH_SIZE], drop_conv: 1.0, drop_hidden: 1.0})\r\n\r\n\r\n# save results\r\nnp.savetxt('submission.csv', \r\n           np.c_[range(1,len(test_images)+1),predicted_lables], \r\n           delimiter=',', \r\n           header = 'ImageId,Label', \r\n           comments = '', \r\n           fmt='%d')\r\n\r\nsess.close()\r\n```\r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}